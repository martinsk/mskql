<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>mskql &mdash; Benchmarks: mskql vs PostgreSQL vs DuckDB</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;0,500;0,600;1,400;1,500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
    <style>
        .caveat {
            border: 1.5px solid var(--accent);
            border-radius: 6px;
            padding: 1rem 1.2rem;
            margin: 1.6rem 0;
            background: #fff;
        }
        .caveat strong { color: var(--accent); }

        .faster { color: #1a7a1a; font-weight: 600; }
        .slower { color: var(--accent); font-weight: 600; }

        td.num, th.num { white-space: nowrap; text-align: right; }

        .group-label td {
            padding-top: 1rem;
            font-variant: small-caps;
            letter-spacing: 0.04em;
            font-size: 0.85rem;
            color: var(--fg-dim);
            border-bottom: 1px solid var(--rule);
        }

        .tp-higher { color: #1a7a1a; font-weight: 600; }
        .tp-lower { color: var(--accent); font-weight: 600; }
    </style>
</head>
<body>

<p class="breadcrumb"><a href="index.html">&larr; mskql</a></p>

<h1>mskql vs PostgreSQL vs DuckDB</h1>
<span class="subtitle">84 batch workloads, 15 throughput workloads, one honest picture</span>
<p class="byline">
    <a href="index.html">&#8592; back to main page</a>
</p>
<hr class="title-rule">

<p>
    <strong>84 batch workloads. 15 concurrent throughput workloads. Three databases on the same machine.</strong>
    On all 28 cached batch workloads and 13 of 15 throughput tests, mskql is faster than PostgreSQL.
    Against DuckDB, mskql wins 37 of 84 workloads&mdash;aggregates 6&times;, expression aggregates 7&times;,
    correlated subqueries 145&times; faster than PG.
    DuckDB wins full scans (4.4&times;) and sorts (4.8&times;).
    PostgreSQL wins mixed read/write (0.96&times;).
</p>

<!-- ═══════════════════════════════════════════════════════════ -->
<!--  WHAT: Setup and framing                                    -->
<!-- ═══════════════════════════════════════════════════════════ -->

<div class="caveat">
    <strong>&#9888; Important caveat.</strong>&ensp;This comparison is <em>unscientific</em>
    and intended only as a directional indicator. As an in-memory database, mskql has
    no durability, no MVCC, no WAL, no background workers, and no query optimizer.
    By contrast, PostgreSQL is a production-grade RDBMS. DuckDB is a columnar analytical engine with
    SIMD vectorization. The numbers below measure wall-clock time for identical SQL
    workloads&mdash;not raw engine speed. Take them as a directional indicator.
</div>

<h2>1. Methodology</h2>

<h3>Batch latency (mskql vs PostgreSQL vs DuckDB)</h3>
<p>
    All three databases are tested on the same Apple&nbsp;M-series laptop, same loopback interface.
    The benchmark script (<code>bench/bench_vs_pg.py</code>) generates identical SQL workloads
    for each test, runs setup against all databases, then times the benchmark queries.
    Each timing measures a single <code>psql&nbsp;-f</code> invocation (mskql, PostgreSQL)
    or <code>duckdb</code> CLI invocation (DuckDB) containing all iterations of that workload.
    Port assignment: mskql on 5433, PostgreSQL on 5432 with default configuration,
    DuckDB in-process via its CLI.
</p>
<p>
    Each workload has two variants: <strong>cached</strong> (result cache active) and
    <strong>no-cache</strong> (<code>_nc</code> suffix&mdash;each query has a unique SQL
    comment appended to bust the result cache). This isolates the effect of mskql&rsquo;s
    result cache from raw execution speed.
</p>

<h3>Concurrent throughput (mskql vs PostgreSQL)</h3>
<p>
    A multi-threaded C benchmark (<code>bench/bench_throughput.c</code>) opens 8 persistent
    connections speaking raw pgwire and fires queries for 5&nbsp;seconds per workload.
    Measures QPS and median latency (p50). DuckDB is not included in throughput tests
    because it does not expose a wire-protocol server.
</p>

<!-- ═══════════════════════════════════════════════════════════ -->
<!--  SO WHAT: The data                                          -->
<!-- ═══════════════════════════════════════════════════════════ -->

<h2>2. Batch Latency &mdash; Cached (single client, sequential)</h2>

<p>
    Ratio &lt;&nbsp;1.0 means mskql was faster. All 28 workloads with PostgreSQL data:
    every one is an mskql win. Against DuckDB: wins on aggregates, joins, CTEs, subqueries;
    DuckDB wins full scans, sorts, wide output.
</p>

<div class="table-scroll">
<table style="table-layout:fixed">
    <colgroup>
        <col style="width:30%">
        <col style="width:10%">
        <col style="width:10%">
        <col style="width:10%">
        <col style="width:10%">
        <col style="width:10%">
    </colgroup>
    <thead>
        <tr>
            <th>Workload</th>
            <th class="num">mskql (ms)</th>
            <th class="num">PG (ms)</th>
            <th class="num">Duck (ms)</th>
            <th class="num">vs PG</th>
            <th class="num">vs Duck</th>
        </tr>
    </thead>
    <tbody>
        <tr class="group-label"><td colspan="6">reads &amp; scans</td></tr>
        <tr>
            <td><strong>Full table scan</strong> <span class="bench-detail">(5K rows &times;200)</span></td>
            <td class="num">306</td><td class="num">460</td><td class="num">69</td>
            <td class="num"><span class="faster">0.66&times;</span></td>
            <td class="num"><span class="slower">4.43&times;</span></td>
        </tr>
        <tr>
            <td><strong>Filtered scan</strong> <span class="bench-detail">(5K rows &times;500)</span></td>
            <td class="num">371</td><td class="num">637</td><td class="num">102</td>
            <td class="num"><span class="faster">0.58&times;</span></td>
            <td class="num"><span class="slower">3.64&times;</span></td>
        </tr>
        <tr>
            <td><strong>Indexed point lookup</strong> <span class="bench-detail">(&times;2K)</span></td>
            <td class="num">107</td><td class="num">110</td><td class="num">95</td>
            <td class="num"><span class="faster">0.97&times;</span></td>
            <td class="num"><span class="slower">1.13&times;</span></td>
        </tr>
        <tr>
            <td><strong>Sort</strong> <span class="bench-detail">(5K rows &times;200)</span></td>
            <td class="num">208</td><td class="num">372</td><td class="num">58</td>
            <td class="num"><span class="faster">0.56&times;</span></td>
            <td class="num"><span class="slower">3.59&times;</span></td>
        </tr>
        <tr>
            <td><strong>Multi-column sort</strong> <span class="bench-detail">(5K rows &times;200)</span></td>
            <td class="num">285</td><td class="num">527</td><td class="num">69</td>
            <td class="num"><span class="faster">0.54&times;</span></td>
            <td class="num"><span class="slower">4.13&times;</span></td>
        </tr>
        <tr>
            <td><strong>Distinct</strong> <span class="bench-detail">(100 categories &times;500)</span></td>
            <td class="num">41</td><td class="num">271</td><td class="num">227</td>
            <td class="num"><span class="faster">0.15&times;</span></td>
            <td class="num"><span class="faster">0.18&times;</span></td>
        </tr>
        <tr class="group-label"><td colspan="6">writes</td></tr>
        <tr>
            <td><strong>Single-row inserts</strong> <span class="bench-detail">(10K)</span></td>
            <td class="num">320</td><td class="num">870</td><td class="num">1,512</td>
            <td class="num"><span class="faster">0.37&times;</span></td>
            <td class="num"><span class="faster">0.21&times;</span></td>
        </tr>
        <tr>
            <td><strong>Bulk insert</strong> <span class="bench-detail">(5K rows)</span></td>
            <td class="num">291</td><td class="num">881</td><td class="num">2,204</td>
            <td class="num"><span class="faster">0.33&times;</span></td>
            <td class="num"><span class="faster">0.13&times;</span></td>
        </tr>
        <tr>
            <td><strong>Bulk update</strong> <span class="bench-detail">(1K of 5K rows &times;200)</span></td>
            <td class="num">51</td><td class="num">248</td><td class="num">1,053</td>
            <td class="num"><span class="faster">0.21&times;</span></td>
            <td class="num"><span class="faster">0.05&times;</span></td>
        </tr>
        <tr>
            <td><strong>Insert + delete</strong> <span class="bench-detail">(2K rows, delete half &times;50)</span></td>
            <td class="num">2,603</td><td class="num">8,937</td><td class="num">20,710</td>
            <td class="num"><span class="faster">0.29&times;</span></td>
            <td class="num"><span class="faster">0.13&times;</span></td>
        </tr>
        <tr>
            <td><strong>Transactional inserts</strong> <span class="bench-detail">(100 txns, 50 each)</span></td>
            <td class="num">178</td><td class="num">192</td><td class="num">1,220</td>
            <td class="num"><span class="faster">0.93&times;</span></td>
            <td class="num"><span class="faster">0.15&times;</span></td>
        </tr>
        <tr class="group-label"><td colspan="6">aggregation &amp; analytics</td></tr>
        <tr>
            <td><strong>Group + sum</strong> <span class="bench-detail">(5K rows &times;500)</span></td>
            <td class="num">35</td><td class="num">290</td><td class="num">212</td>
            <td class="num"><span class="faster">0.12&times;</span></td>
            <td class="num"><span class="faster">0.16&times;</span></td>
        </tr>
        <tr>
            <td><strong>Expression aggregate</strong> <span class="bench-detail">(SUM(price&times;qty) &times;500)</span></td>
            <td class="num">35</td><td class="num">331</td><td class="num">239</td>
            <td class="num"><span class="faster">0.10&times;</span></td>
            <td class="num"><span class="faster">0.14&times;</span></td>
        </tr>
        <tr>
            <td><strong>Wide aggregate</strong> <span class="bench-detail">(7 cols, 50K rows &times;20)</span></td>
            <td class="num">24</td><td class="num">167</td><td class="num">131</td>
            <td class="num"><span class="faster">0.14&times;</span></td>
            <td class="num"><span class="faster">0.18&times;</span></td>
        </tr>
        <tr>
            <td><strong>Window function</strong> <span class="bench-detail">(ROW_NUMBER, 5K &times;20)</span></td>
            <td class="num">54</td><td class="num">95</td><td class="num">29</td>
            <td class="num"><span class="faster">0.57&times;</span></td>
            <td class="num"><span class="slower">1.86&times;</span></td>
        </tr>
        <tr>
            <td><strong>Window function</strong> <span class="bench-detail">(RANK, 50K rows &times;5)</span></td>
            <td class="num">131</td><td class="num">236</td><td class="num">36</td>
            <td class="num"><span class="faster">0.55&times;</span></td>
            <td class="num"><span class="slower">3.64&times;</span></td>
        </tr>
        <tr>
            <td><strong>Correlated subquery</strong></td>
            <td class="num">24</td><td class="num">3,498</td><td class="num">38</td>
            <td class="num"><span class="faster">0.01&times;</span></td>
            <td class="num"><span class="faster">0.64&times;</span></td>
        </tr>
        <tr class="group-label"><td colspan="6">joins, subqueries &amp; complex queries</td></tr>
        <tr>
            <td><strong>Two-table join</strong> <span class="bench-detail">(500 + 2K rows &times;50)</span></td>
            <td class="num">29</td><td class="num">64</td><td class="num">29</td>
            <td class="num"><span class="faster">0.45&times;</span></td>
            <td class="num"><span class="faster">1.00&times;</span></td>
        </tr>
        <tr>
            <td><strong>Three-table join + group</strong> <span class="bench-detail">(50K rows &times;5)</span></td>
            <td class="num">36</td><td class="num">108</td><td class="num">35</td>
            <td class="num"><span class="faster">0.33&times;</span></td>
            <td class="num"><span class="slower">1.03&times;</span></td>
        </tr>
        <tr>
            <td><strong>Subquery filter</strong> <span class="bench-detail">(IN subquery &times;50)</span></td>
            <td class="num">44</td><td class="num">101</td><td class="num">32</td>
            <td class="num"><span class="faster">0.44&times;</span></td>
            <td class="num"><span class="slower">1.38&times;</span></td>
        </tr>
        <tr>
            <td><strong>Subquery pipeline</strong> <span class="bench-detail">(filter + sort + limit, 50K &times;20)</span></td>
            <td class="num">28</td><td class="num">141</td><td class="num">22</td>
            <td class="num"><span class="faster">0.20&times;</span></td>
            <td class="num"><span class="slower">1.27&times;</span></td>
        </tr>
        <tr>
            <td><strong>CTE filter chain</strong> <span class="bench-detail">(5K rows &times;200)</span></td>
            <td class="num">54</td><td class="num">121</td><td class="num">39</td>
            <td class="num"><span class="faster">0.45&times;</span></td>
            <td class="num"><span class="slower">1.38&times;</span></td>
        </tr>
        <tr>
            <td><strong>CTE pipeline</strong> <span class="bench-detail">(agg &rarr; sort &rarr; limit, 50K &times;20)</span></td>
            <td class="num">61</td><td class="num">81</td><td class="num">22</td>
            <td class="num"><span class="faster">0.75&times;</span></td>
            <td class="num"><span class="slower">2.77&times;</span></td>
        </tr>
        <tr>
            <td><strong>Analytical CTE</strong> <span class="bench-detail">(join&rarr;agg&rarr;sort, 50K &times;5)</span></td>
            <td class="num">22</td><td class="num">78</td><td class="num">35</td>
            <td class="num"><span class="faster">0.28&times;</span></td>
            <td class="num"><span class="faster">0.61&times;</span></td>
        </tr>
        <tr>
            <td><strong>Union</strong> <span class="bench-detail">(two 2K-row tables &times;50)</span></td>
            <td class="num">57</td><td class="num">103</td><td class="num">24</td>
            <td class="num"><span class="faster">0.55&times;</span></td>
            <td class="num"><span class="slower">2.38&times;</span></td>
        </tr>
        <tr class="group-label"><td colspan="6">functions &amp; generation</td></tr>
        <tr>
            <td><strong>Generate series</strong> <span class="bench-detail">(10K rows &times;200)</span></td>
            <td class="num">219</td><td class="num">688</td><td class="num">40</td>
            <td class="num"><span class="faster">0.32&times;</span></td>
            <td class="num"><span class="slower">5.48&times;</span></td>
        </tr>
        <tr>
            <td><strong>Scalar functions</strong> <span class="bench-detail">(4 functions, 5K rows &times;200)</span></td>
            <td class="num">390</td><td class="num">980</td><td class="num">74</td>
            <td class="num"><span class="faster">0.40&times;</span></td>
            <td class="num"><span class="slower">5.27&times;</span></td>
        </tr>
        <tr class="group-label"><td colspan="6">large dataset (50K rows)</td></tr>
        <tr>
            <td><strong>Large sort</strong> <span class="bench-detail">(50K rows &times;10)</span></td>
            <td class="num">246</td><td class="num">365</td><td class="num">51</td>
            <td class="num"><span class="faster">0.67&times;</span></td>
            <td class="num"><span class="slower">4.83&times;</span></td>
        </tr>
    </tbody>
</table>
</div>

<p>
    <strong>All 28 cached workloads faster than PostgreSQL.</strong> Closest: index lookups
    (0.97&times;), transactions (0.93&times;). Against DuckDB: mskql wins aggregates,
    distinct, writes, analytical CTE, correlated subquery. DuckDB wins scans, sorts,
    window functions, generate_series, scalar functions.
    See <a href="bench-workloads.html">workload details</a> for the exact SQL.
</p>

<h2 id="parquet">3. Parquet Benchmarks &mdash; mskql vs DuckDB</h2>

<p>
    9 Parquet workloads (50K&ndash;200K rows). PostgreSQL cannot query Parquet files natively,
    so this section compares mskql and DuckDB only. The mskql side uses <code>CREATE FOREIGN TABLE</code>;
    DuckDB uses its native Parquet reader.
</p>

<div class="table-scroll">
<table style="table-layout:fixed">
    <colgroup>
        <col style="width:26%">
        <col style="width:10%">
        <col style="width:10%">
        <col style="width:10%">
        <col style="width:10%">
        <col style="width:34%">
    </colgroup>
    <thead>
        <tr>
            <th>Workload</th>
            <th class="num">mskql (ms)</th>
            <th class="num">Duck (ms)</th>
            <th class="num">Cached</th>
            <th class="num">No-cache</th>
            <th>Notes</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><strong>pq_full_scan</strong> <span class="bench-detail">(50K rows)</span></td>
            <td class="num">449</td><td class="num">32</td>
            <td class="num"><span class="slower">14.0&times;</span></td>
            <td class="num"><span class="slower">14.0&times;</span></td>
            <td>Row-by-row Parquet read; no columnar pushdown yet</td>
        </tr>
        <tr>
            <td><strong>pq_where</strong> <span class="bench-detail">(filtered scan, 50K rows)</span></td>
            <td class="num">22</td><td class="num">44</td>
            <td class="num"><span class="faster">0.50&times;</span></td>
            <td class="num"><span class="slower">2.18&times;</span></td>
            <td>Result cache bypasses Parquet I/O on repeat</td>
        </tr>
        <tr>
            <td><strong>pq_aggregate</strong> <span class="bench-detail">(GROUP BY, 50K rows)</span></td>
            <td class="num">28</td><td class="num">76</td>
            <td class="num"><span class="faster">0.37&times;</span></td>
            <td class="num"><span class="slower">1.42&times;</span></td>
            <td>Columnar hash aggregation on cached data</td>
        </tr>
        <tr>
            <td><strong>pq_order_by</strong> <span class="bench-detail">(sort, 50K rows)</span></td>
            <td class="num">371</td><td class="num">29</td>
            <td class="num"><span class="slower">12.8&times;</span></td>
            <td class="num"><span class="slower">12.8&times;</span></td>
            <td>Sort requires full materialization; DuckDB sorts columnar natively</td>
        </tr>
        <tr>
            <td><strong>pq_wide_agg</strong> <span class="bench-detail">(7 cols, 50K rows)</span></td>
            <td class="num">27</td><td class="num">42</td>
            <td class="num"><span class="faster">0.65&times;</span></td>
            <td class="num"><span class="slower">1.95&times;</span></td>
            <td>Multi-column agg stays in L1 cache</td>
        </tr>
        <tr>
            <td><strong>pq_join_two</strong> <span class="bench-detail">(50K + 2K rows)</span></td>
            <td class="num">28</td><td class="num">35</td>
            <td class="num"><span class="faster">0.80&times;</span></td>
            <td class="num"><span class="slower">3.14&times;</span></td>
            <td>Hash join on cached Parquet data</td>
        </tr>
        <tr>
            <td><strong>pq_join_three</strong> <span class="bench-detail">(3 Parquet files)</span></td>
            <td class="num">30</td><td class="num">38</td>
            <td class="num"><span class="faster">0.79&times;</span></td>
            <td class="num"><span class="slower">3.42&times;</span></td>
            <td>Three-way join across Parquet files</td>
        </tr>
        <tr>
            <td><strong>pq_subquery</strong> <span class="bench-detail">(IN subquery, 2 files)</span></td>
            <td class="num">21</td><td class="num">44</td>
            <td class="num"><span class="faster">0.49&times;</span></td>
            <td class="num"><span class="slower">2.05&times;</span></td>
            <td>Hash semi-join on cached result</td>
        </tr>
        <tr>
            <td><strong>pq_analytical</strong> <span class="bench-detail">(CTE + join + agg, 3 files)</span></td>
            <td class="num">29</td><td class="num">41</td>
            <td class="num"><span class="faster">0.71&times;</span></td>
            <td class="num"><span class="slower">2.93&times;</span></td>
            <td>Full analytical pipeline on Parquet</td>
        </tr>
    </tbody>
</table>
</div>

<p>
    <strong>Cached: mskql wins 7 of 9.</strong> The result cache serves repeated Parquet
    queries from cached wire bytes. DuckDB re-reads the Parquet file every time.
    <strong>No-cache: DuckDB wins 8 of 9.</strong> DuckDB&rsquo;s native columnar Parquet
    reader is faster on cold reads. On the mskql side, Parquet is read row-by-row via
    <code>PLAN_PARQUET_SCAN</code>&mdash;no columnar pushdown yet.
</p>

<h2>4. Concurrent Throughput (8 threads, 5&nbsp;seconds)</h2>

<p>
    Comparison: mskql vs PostgreSQL only&mdash;DuckDB does not expose a wire-protocol server.
    Ratio &gt;&nbsp;1.0 means mskql has higher throughput.
</p>

<div class="table-scroll">
<table style="table-layout:fixed">
    <colgroup>
        <col style="width:28%">
        <col style="width:14%">
        <col style="width:14%">
        <col style="width:10%">
        <col style="width:34%">
    </colgroup>
    <thead>
        <tr>
            <th>Workload</th>
            <th class="num">mskql QPS</th>
            <th class="num">PG QPS</th>
            <th class="num">Ratio</th>
            <th>Notes</th>
        </tr>
    </thead>
    <tbody>
        <tr class="group-label"><td colspan="5">simple reads &amp; writes</td></tr>
        <tr>
            <td><strong>Indexed point lookup</strong></td>
            <td class="num">78,600</td><td class="num">23,461</td>
            <td class="num"><span class="tp-higher">3.35&times;</span></td>
            <td>mskql 0.101ms p50 vs PG 0.254ms</td>
        </tr>
        <tr>
            <td><strong>Full table scan</strong> <span class="bench-detail">(5K rows)</span></td>
            <td class="num">121</td><td class="num">120</td>
            <td class="num"><span class="tp-higher">1.00&times;</span></td>
            <td>Network-bound: both ~66ms p50</td>
        </tr>
        <tr>
            <td><strong>Filtered scan</strong> <span class="bench-detail">(5K rows)</span></td>
            <td class="num">245</td><td class="num">241</td>
            <td class="num"><span class="tp-higher">1.02&times;</span></td>
            <td>Network-bound: both ~33ms p50</td>
        </tr>
        <tr>
            <td><strong>Single-row insert</strong></td>
            <td class="num">63,253</td><td class="num">39,189</td>
            <td class="num"><span class="tp-higher">1.61&times;</span></td>
            <td>No fsync, no WAL</td>
        </tr>
        <tr>
            <td><strong>Mixed read/write</strong> <span class="bench-detail">(80/20)</span></td>
            <td class="num">55,680</td><td class="num">58,001</td>
            <td class="num"><span class="tp-lower">0.96&times;</span></td>
            <td>PG&rsquo;s MVCC wins on concurrent writes</td>
        </tr>
        <tr class="group-label"><td colspan="5">aggregation &amp; analytics</td></tr>
        <tr>
            <td><strong>Group + sum</strong> <span class="bench-detail">(5K rows)</span></td>
            <td class="num">95,044</td><td class="num">13,929</td>
            <td class="num"><span class="tp-higher">6.82&times;</span></td>
            <td>Result cache: 0.084ms p50</td>
        </tr>
        <tr>
            <td><strong>Wide aggregate</strong> <span class="bench-detail">(50K rows)</span></td>
            <td class="num">8,373</td><td class="num">1,036</td>
            <td class="num"><span class="tp-higher">8.08&times;</span></td>
            <td>Result cache: 0.952ms p50</td>
        </tr>
        <tr>
            <td><strong>Window function</strong> <span class="bench-detail">(RANK, 50K rows)</span></td>
            <td class="num">14</td><td class="num">12</td>
            <td class="num"><span class="tp-higher">1.22&times;</span></td>
            <td>Both slow: 50K-row window is CPU-bound</td>
        </tr>
        <tr class="group-label"><td colspan="5">complex queries (50K-row dataset)</td></tr>
        <tr>
            <td><strong>Two-table join</strong> <span class="bench-detail">(500 + 2K rows)</span></td>
            <td class="num">562</td><td class="num">302</td>
            <td class="num"><span class="tp-higher">1.86&times;</span></td>
            <td></td>
        </tr>
        <tr>
            <td><strong>Multi-join</strong> <span class="bench-detail">(3 tables)</span></td>
            <td class="num">36,273</td><td class="num">462</td>
            <td class="num"><span class="tp-higher">78.5&times;</span></td>
            <td>Result cache: 0.221ms p50</td>
        </tr>
        <tr>
            <td><strong>Mixed analytical</strong> <span class="bench-detail">(CTE&rarr;join&rarr;agg&rarr;sort)</span></td>
            <td class="num">94,729</td><td class="num">689</td>
            <td class="num"><span class="tp-higher">137&times;</span></td>
            <td>Result cache: 0.085ms p50</td>
        </tr>
        <tr>
            <td><strong>CTE pipeline</strong> <span class="bench-detail">(agg&rarr;sort&rarr;limit)</span></td>
            <td class="num">5,606</td><td class="num">1,920</td>
            <td class="num"><span class="tp-higher">2.92&times;</span></td>
            <td></td>
        </tr>
        <tr>
            <td><strong>Subquery pipeline</strong> <span class="bench-detail">(filter+sort+limit)</span></td>
            <td class="num">1,170</td><td class="num">898</td>
            <td class="num"><span class="tp-higher">1.30&times;</span></td>
            <td></td>
        </tr>
        <tr>
            <td><strong>Large sort</strong> <span class="bench-detail">(50K rows)</span></td>
            <td class="num">30</td><td class="num">12</td>
            <td class="num"><span class="tp-higher">2.54&times;</span></td>
            <td></td>
        </tr>
    </tbody>
</table>
</div>

<!-- ═══════════════════════════════════════════════════════════ -->
<!--  SO WHAT: The honest picture                                -->
<!-- ═══════════════════════════════════════════════════════════ -->

<h2>5. The Honest Picture</h2>

<h3>Where mskql wins</h3>

<p>
    <strong>vs PostgreSQL: all 28 cached batch workloads.</strong>
    Correlated subquery: 24ms vs 3,498ms (145&times;). Expression aggregate: 35ms vs 331ms (10&times;).
    Throughput: mixed_analytical at 94,729 QPS vs 689 (137&times;). multi_join at 36,273 vs 462 (78&times;).
    The result cache and zero-allocation executor dominate on repeated analytical queries.
</p>

<p>
    <strong>vs DuckDB: aggregates, writes, correlated subqueries, analytical CTEs.</strong>
    Expression aggregate: 35ms vs 239ms (7&times;). Aggregate: 35ms vs 212ms (6&times;).
    Insert+delete: 2,603ms vs 20,710ms (8&times;). Bulk update: 51ms vs 1,053ms (21&times;).
    Analytical CTE: 22ms vs 35ms (1.6&times;). Correlated subquery: 24ms vs 38ms (1.6&times;).
</p>

<p>
    <strong>Parquet (cached): 7 of 9 workloads.</strong>
    pq_aggregate: 28ms vs 76ms (2.7&times;). pq_subquery: 21ms vs 44ms (2&times;).
    The result cache makes repeated Parquet queries faster than DuckDB&rsquo;s native reader.
</p>

<h3>Where DuckDB wins</h3>

<p>
    <strong>Full scans: 4.4&times; faster.</strong> DuckDB&rsquo;s columnar storage reads
    contiguous column data with SIMD vectorization. The mskql row store converts to
    columnar via the scan cache&mdash;fast, but not as fast as native columnar.
</p>

<p>
    <strong>Sorts: 4.8&times; faster.</strong> DuckDB&rsquo;s sort is SIMD-optimized for
    columnar data. The mskql plan executor sorts via qsort on column blocks.
</p>

<p>
    <strong>Window functions: 1.9&ndash;3.6&times; faster.</strong> DuckDB&rsquo;s window
    function implementation is heavily optimized for columnar processing.
</p>

<p>
    <strong>Parquet (cold): 8 of 9 workloads.</strong> DuckDB reads Parquet natively
    with columnar pushdown. The mskql Parquet reader scans row-by-row via <code>PLAN_PARQUET_SCAN</code>.
</p>

<h3>Where PostgreSQL wins</h3>

<p>
    <strong>Mixed read/write throughput: 0.96&times;.</strong>
    PostgreSQL&rsquo;s MVCC allows concurrent readers and writers without blocking.
    The mskql single-threaded executor serializes all queries.
</p>

<!-- ═══════════════════════════════════════════════════════════ -->
<!--  NOW WHAT: Reproduction                                     -->
<!-- ═══════════════════════════════════════════════════════════ -->

<h2>6. Running It Yourself</h2>

<h3>Batch latency (3-way)</h3>
<pre><code class="language-bash"># Start mskql in one terminal
./build/mskql

# In another terminal, with PostgreSQL and DuckDB installed:
./bench/bench_vs_pg.sh</code></pre>

<h3>Concurrent throughput (mskql vs PG)</h3>
<pre><code class="language-bash"># Build the throughput benchmark
make -C bench bench_throughput

# Run (requires both mskql and PostgreSQL running)
./build/mskql_bench_tp --duration 5 --threads 8 --pg</code></pre>

<p>
    The batch script auto-creates a <code>mskql_bench</code> database in PostgreSQL if it
    doesn&rsquo;t exist. DuckDB runs in-process via its CLI. The throughput benchmark
    requires <code>libpq</code> headers at build time.
</p>

<footer class="site-footer">
    <a href="https://www.linkedin.com/in/martinskristiansen">Martin S. Kristiansen</a>
    &ensp;&middot;&ensp;
    <a href="https://github.com/martinsk/mskql">Source on GitHub</a>
    &ensp;&middot;&ensp;
    <a href="index.html">Documentation</a>
</footer>

</body>
</html>
